{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"19n-Yyewc0WxdrAM2DmN7BMt7u5lghdMh","authorship_tag":"ABX9TyNG3Vu/9Fu7LUbMqp4dcLBn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FqRQaDOxyN0I"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n","import matplotlib.pyplot as plt\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier as RFC\n","from sklearn.tree import DecisionTreeClassifier as DTC\n","from sklearn.ensemble import GradientBoostingClassifier as GBC\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix, f1_score"]},{"cell_type":"code","source":["# 레드 와인데이터셋 불러오기\n","red = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n","# 화이트 와인데이터셋 불러오기\n","white = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')"],"metadata":{"id":"o5bpDr7IzGDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red.head(2)"],"metadata":{"id":"9NEdHGVqzfLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white.head(3)"],"metadata":{"id":"L2uY724S0k3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red.columns"],"metadata":{"id":"4PNVB-rh07Gm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red = red.drop(['quality'], axis = 1)\n","white = white.drop(['quality'], axis = 1)"],"metadata":{"id":"FAFL2JKb1Nop"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red.head(3)"],"metadata":{"id":"DOvp-xXG1c59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white.head(3)"],"metadata":{"id":"6tPie1Am1ecS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red.isnull().sum()"],"metadata":{"id":"_JnYbBbH1fUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white.isnull().sum()"],"metadata":{"id":"4m85BYpR1jUG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이상치 제거 - boxplot 시각화\n","def boxplot_vis(data, target_name):\n","    plt.figure(figsize = (30, 30))\n","    for col_idx in range(len(data.columns)):\n","        plt.subplot(6, 2, col_idx+1)\n","        plt.boxplot(data[data.columns[col_idx]],\n","                         flierprops = dict(markerfacecolor = 'r',\n","                                           marker = 'D'))\n","        plt.title('feature' + '(' + target_name + '):' + data.columns[col_idx],\n","                  fontsize = 20)\n","    plt.savefig('/content/drive/MyDrive/Colab Notebooks/figure/boxplot_' + target_name + '.png')\n","    plt.show()        "],"metadata":{"id":"gIMOrGhD1od6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_outlier(input_data):\n","    q1 = input_data.quantile(0.25)\n","    q3 = input_data.quantile(0.75)\n","    iqr = q3 - q1\n","    minimum = q1 - (iqr*1.5)\n","    maximum = q3 + (iqr*1.5)\n","    df_removed_outlier = input_data[(minimum < input_data) & (input_data < maximum)]\n","    return df_removed_outlier"],"metadata":{"id":"hSpqU_PV8ZYZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["boxplot_vis(red, 'red')"],"metadata":{"id":"dFNTxKZs33QD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red_prep = remove_outlier(red)"],"metadata":{"id":"aJaVV4hN87vA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 목표변수 할당\n","red_prep['target'] = 0"],"metadata":{"id":"M4ujXXN08-pZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red_prep.isnull().sum()"],"metadata":{"id":"tb7E-TQ99Iq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["red_prep.head(3)"],"metadata":{"id":"lBHFFWNy9LqV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이상치 포함 데이터(이상치 처리 후 NaN) 삭제\n","red_prep.dropna(axis = 0, how = 'any', inplace = True)\n","print(f'이상치 포함된 데이터 비율: {round((len(red) - len(red_prep))*100/len(red), 2)}%')"],"metadata":{"id":"8bnr4kP7_sRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white_prep = remove_outlier(white)"],"metadata":{"id":"Reehf01nBZR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white_prep['target'] = 1"],"metadata":{"id":"fiizF3OkBfDi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white_prep.isnull().sum()"],"metadata":{"id":"xNtFoxSjBi4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["white_prep.dropna(axis = 0, how = 'any', inplace = True)\n","print( f'이상치 포함된 비율: {round((len(white) - len(white_prep))*100/len(white), 2)}%')"],"metadata":{"id":"GjMpeFGoBl4h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 저장\n","red_prep.to_csv('/content/drive/MyDrive/Colab Notebooks/red_prep.csv')\n","white_prep.to_csv('/content/drive/MyDrive/Colab Notebooks/white_prep.csv')"],"metadata":{"id":"j6D1mwMpOWO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 병합\n","# Now combine RED WINE and WHITE WINE data using concat module on Pandas\n","df = pd.concat([red_prep, white_prep], axis = 0)\n","df.head()"],"metadata":{"id":"ZA4mbTWKB3R9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save combined dataset\n","df.to_csv('/content/drive/MyDrive/Colab Notebooks/wine_combined.csv')"],"metadata":{"id":"uo4KQAQyOPJd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the wine ratio\n","print(df.target.value_counts(normalize=True))\n","print(df.target.value_counts())"],"metadata":{"id":"A70rr2YBPF0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 설명변수별 목표변수 간의 관계 시각화\n","# 설명변수 1개씩 반복문을 통해 선정한 후 레드 와인과 화이트 와인 각각에 해당하는 데이터를 histogram으로 표현"],"metadata":{"id":"Ao8aTHGjPPin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = df[df.columns.difference(['target'])]\n","# 설명변수명 리스트\n","feature_name = x.columns\n","plt.figure(figsize = (10, 25))\n","for col_idx in range(len(feature_name)):\n","      # 6행 2열 서브플롯에 각 feature boxplot 시각화\n","      plt.subplot(6, 2, col_idx+1)\n","      plt.hist(df[df['target'] == 0][feature_name[col_idx]],\n","               label = 'Red wine',\n","               alpha = 0.5)\n","      plt.hist(df[df['target'] == 1][feature_name[col_idx]],\n","               label = 'White wine',\n","               alpha = 0.5)\n","      plt.legend()\n","      plt.title('Feature: ' + feature_name[col_idx],\n","                fontsize = 10)\n","plt.show()"],"metadata":{"id":"xIPsWFczQLBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data scaling\n","scaler = StandardScaler()\n","# 목표변수 분리 & 설명변수 데이터 스케일링\n","y = df['target']\n","x_scaled = scaler.fit_transform(x)"],"metadata":{"id":"cHUYViGWRuY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split data set\n","x_train, x_test, y_train, y_test = train_test_split(x_scaled, y,\n","                                                    test_size = 0.3,\n","                                                    random_state = 123)"],"metadata":{"id":"_I2edowMSvxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train.value_counts(normalize=True)"],"metadata":{"id":"2TDpXePWS_sH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test.value_counts(normalize=True)"],"metadata":{"id":"1Ts6V9_uTFLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classefier 모델링 함수\n","# 기본 모델 학습 함수\n","def modeling_uncustomized(algorithm, x_train, y_train, x_test, y_test):\n","    # 하이퍼파라미터 조정 없이 모델 학습\n","    uncustomized = algorithm(random_state = 1234)\n","    uncustomized.fit(x_train, y_train)\n","    # train and test data 설명력\n","    train_score_before = uncustomized.score(x_train, y_train).round(3)\n","    print(f'학습 데이터셋 정확도: {train_score_before}')\n","    test_score_before = uncustomized.score(x_test, y_test).round(3)\n","    print(f'테스트 데이터셋 정확도: {test_score_before}')\n","    return train_score_before, test_score_before\n"],"metadata":{"id":"dH2DnNDVTIQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 하이퍼파라미터별 모델 성능 시각화 함수\n","def optimi_visualization(algorithm_name, x_values, train_score, test_score,\n","                         xlabel, filename):\n","      # 하이퍼 파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n","      plt.plot(x_values, train_score, linestyle = '-', label = 'train score')\n","      # 하이퍼 파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n","      plt.plot(x_values, test_score, linestyle = '--', label = 'test score')\n","      plt.ylabel('Accuracy(%)')   # y축 레이블\n","      plt.xlabel(xlabel)          # x축 레이블\n","      plt.legend()                # 범례표시"],"metadata":{"id":"mM7WeddAT8XA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 최적화 함수 : 학습할 트리 모델 개수 선정\n","def optimi_estimator(algorithm, algorithm_name, x_train, y_train, x_test, y_test,\n","                     n_estimator_min, n_estimator_max):\n","    train_score = [] ; test_score = []\n","    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n","\n","    for v_n_estimators in para_n_tree:\n","        model = algorithm(n_estimators = v_n_estimators, random_state = 1234)\n","        model.fit(x_train, y_train)\n","        train_score.append(model.score(x_train, y_train))\n","        test_score.append(model.score(x_test, y_test))\n","    # 트리 개수에 따른 모델 성능 저장\n","    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n","    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n","    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, 'The number of estimator', 'n_estimator')\n","    print(round(df_score_n, 4))"],"metadata":{"id":"xG-Rz6O6UsHZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화 함수: 최대 깊이 선정\n","   * 다음은 모델이 학습할 트리별 최대 깊이를 결정하기 위한 함수입니다.\n","   * 전달받은 최대 깊이의 최소값부터 깊이를 1씩 최대 깊이의 최대값까지 늘려가며 모델의 성능을 평가합니다.\n","   * 모델 성능은 앞서 작성한 시각화 함수에 전달하여 하이퍼파라미터에 따른 성능 변화 추이를 시각황합니다."],"metadata":{"id":"1uSJInR7hDCW"}},{"cell_type":"code","source":["def optimi_maxdepth(algorithm, algorithm_name, x_train, y_train, x_test, y_test,\n","                    depth_min, depth_max, n_etsimator):\n","    train_score = []; test_score = []\n","    para_depth = [depth for depth in range(depth_min, depth_max)]\n","    \n","    for v_max_depth in para_depth:\n","        # 의사결정나무 모델의 경우 트리 갯수를 따로 설정하지 않기 때문에, RFC, GBC와 분리하여 모델링\n","        if algorithm == DTC:\n","            model = algorithm(max_depth = v_max_depth,\n","                              random_state = 1234)\n","        else:\n","            model = algorithm(max_depth = v_max_depth,\n","                              n_estimators = n_estimator,\n","                              random_state = 1234)\n","\n","        model.fit(x_train, y_train)\n","        train_score.append(model.score(x_train, y_train))\n","        test_score.append(model.score(x_test, y_test))\n","\n","    # 최대 깊이에 따른 모델 성능 저장\n","    df_score_n = pd.DataFrame({'depth': para_depth,\n","                               'TrainScore': train_score,\n","                               'TestScore': test_score})\n","    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n","    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n","    print(round(df_score_n, 4))"],"metadata":{"id":"EThbBgngg22r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화 함수: 분리 노드의 최소 자료 수 선정\n","* 노드를 분리하기 위한 최소 자료 수를 결정하기 위한 함수\n","* 전달받은 분리 노드의 최소 자료 수의 최소값부터 깊이를 2씩 \n","* 분리 노드의 최소 자료 수의 최대값까지 늘려가며 모델의 성능을 평가합니다\n","* 모델 성능은 앞서 작성한 시각화 함수에 전달하여 하이퍼파라미터에 따른 성능 변화 추이를 시각화합니다. "],"metadata":{"id":"WimrXWhdUp7J"}},{"cell_type":"code","source":["def optimi_minsplit (algorithm, algorithm_name, x_train, y_train, x_test, y_test,\n","                     n_split_min, n_split_max, n_estimator, n_depth ):\n","    train_score = []; test_score = []\n","    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n","    for v_min_samples_split in para_split:\n","        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 \n","        # RFC, GBC와 분리하여 모델링\n","        if algorithm == DTC:\n","            model = algorithm(min_samples_split = v_min_samples_split,\n","                              max_depth = n_depth,\n","                              random_state = 1234)\n","        else:\n","            model = algorithm(min_samples_split = v_min_samples_split,\n","                              n_estimators = n_estimator,\n","                              max_depth = n_depth,\n","                              random_state = 1234\n","                              )\n","        model.fit(x_train, y_train)\n","        train_score.append(model.score(x_train, y_train))\n","        test_score.append(model.score(x_test, y_test))\n","\n","    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n","    df_score_n = pd.DataFrame({'min_samples_split': para_split,\n","                               'TrainScore': train_score,\n","                               'TestScore': test_score\n","                               })\n","    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n","    optimi_visualization(algorithm_name, para_split, train_score, test_score,\n","                         'The minimum number of samples required to split an internal node',\n","                         'min_samples_split'\n","                         )\n","    print(round(df_score_n, 4))"],"metadata":{"id":"SAamJYW1WBZa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화 함수: 잎사귀 노드의 최소 자료 수 선정\n","   * 다음은 잎사귀 노드 내 최소 자료 수를 결정하기 위한 함수입니다.\n","   * 전달받은 잎사귀 노드의 최소 자료 수의 최소값부터 깊이를 2씩\n","   * 잎사귀 노드의 최소 자료 수의 최대값까지 늘려가며 모델의 성능을 평가합니다.\n","   * 모델 성능은 앞서 작성한 시각화 함수에 전달하여 하이퍼파라미터에 따른 성능 변화 추이를 시각화합니다. "],"metadata":{"id":"UCm-WjoJW9WZ"}},{"cell_type":"code","source":["def optimi_minleaf(algorithm, algorithm_name, x_train, y_train, x_test, y_test,\n","                   n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n","    train_score = []; test_score = []\n","    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n","\n","    for v_min_samples_leaf in para_leaf:\n","        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링 \n","        if algorithm == DTC:\n","            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n","                              max_depth = n_depth,\n","                              min_samples_split = n_split,\n","                              random_state = 1234 )\n","        else:\n","            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n","                              n_estimators = n_estimator,\n","                              max_depth = n_depth,\n","                              min_samples_split = n_split,\n","                              random_state = 1234)\n","        model.fit(x_train, y_train)\n","        train_score.append(model.score(x_train, y_train))\n","        test_score.append(model.score(x_test, y_test))\n","\n","    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n","    df_score_n = pd.DataFrame({'min_sampels_leaf': para_leaf,\n","                               'TrainScore': train_score,\n","                               'TestScore': test_score\n","                               })\n","    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n","    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n","    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n","    optimi_visualization(algorithm_name, para_leaf, train_score, test_score,\n","                         \"The minimum number of samples required to be at a leaf node\", \n","                         \"min_samples_leaf\")\n","    print(round(df_score_n, 4))"],"metadata":{"id":"DtlbxW8HW8Ai"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 최종 모델 학습\n","   * 앞서 구한 최적의 하이퍼파라미터 기반으로 최종 모델을 학습합니다.\n","   * 학습한 모델을 pickle 모듈을 통해 저장합니다.\n","   * 모델 성능 평가를 위해 평가지표로서 Accuracy, Precision, Recall, F1 score, Confusion Matrix를 활용합니다.\n","   * 마지막으로 변수별 중요도를 산출하고 시각화합니다."],"metadata":{"id":"WKEc4VvBZRO0"}},{"cell_type":"code","source":["def model_final(algorithm, algorithm_name, feature_name, x_train, y_train, x_test, y_test,\n","                n_estimator, n_depth, n_split, n_leaf):\n","    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n","    if algorithm == DTC:\n","        model = algorithm(random_state = 1234,\n","                          min_samples_leaf = n_leaf,\n","                          min_samples_split = n_split,\n","                          max_depth = n_depth)\n","    else:\n","        model = algorithm(random_state = 1234,\n","                          n_estimators = n_estimator,\n","                          min_samples_leaf = n_leaf,\n","                          min_samples_split = n_split,\n","                          max_depth = n_depth)\n","    # 모델 학습\n","    model.fit(x_train, y_train)\n","    # 모델 저장\n","    model_path = '/content/drive/MyDrive/Colab Notebooks/model/'\n","    model_filename = 'wine_classification_' + algorithm_name + '.pkl'\n","    with open(model_path + model_filename, 'wb') as f:\n","        pickle.dump(model, f)\n","    print(f'최종 모델 저장 완료! 파일 경로: {model_path + model_filename}\\n')\n","\n","    # 최종 모델의 성능 평가\n","    train_acc = model.score(x_train, y_train)\n","    test_acc = model.score(x_test, y_test)\n","    y_pred = model.predict(x_test)\n","    print(f'Accuracy: {accuracy_score(y_test, y_pred):.3f}')    # 정확도\n","    print(f'Precision: {precision_score(y_test, y_pred):.3f}')  # 정밀도\n","    print(f'Recall: {recall_score(y_test, y_pred):.3f}')        # 재현율\n","    print(f'F1-score: {f1_score(y_test, y_pred):.3f}')          # F1 스코어\n","\n","    # Confusion matrix\n","    plt.figure(firsize = (30, 30))\n","    plot_confusion_matrix(model,\n","                          x_test, y_test,\n","                          include_values = True,\n","                          display_labels = ['Red', 'White'],    # 목표변수 이름\n","                          cmap = 'Pastel1')                     # 컬러맵\n","    plt.savefig('/content/drive/MyDrive/Colab Notebooks/figure/' + algorithm_name + '_confusion_matrix.png')  # 혼동행렬\n","    plt.show()\n","\n","    # 변수 중요도 산출\n","    dt_importance = pd.DataFrame()\n","    dt_importance['Feature'] = feature_name       # 설명변수 이름\n","    dt_importance['Importance'] = model.feature_importances_    # 설명변수 중요도 산출\n","\n","    # 변수 중요도 내림차순 정렬\n","    dt_importance.sort_values('Importance', ascending = False, inplace = True)\n","    print(dt_importance.round(3))\n","    # 변수 중요도 시각화\n","    coordinates = range(len(dt_importance))               # 설명변수 개수만큼 bar 시각화\n","    plt.barh(y = coordinates, width = dt_importance['Importance'])\n","    plt.yticks(coordinates, dt_importance['Feature'])     # y축 눈금별 설명변수 이름 기입\n","    plt.xlabel('Feature Importance')                      # x축 이름\n","    plt.ylabel('Features')                                # y축 이름\n","    plt.savefig('/content/drive/MyDrive/Colab Notebooks/figure/' + algorithm_name + '_feature_importance.png')   # 변수 중요도 그래프 저장"],"metadata":{"id":"MFWoOPQhZNJS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Random Forest Classifier 기반 분류 모델 성능 평가\n","\n","   * 라이브러리를 import 할 때 RandomForestClassifier를 RFC로 치환하였습니다.\n","   * 본 포스팅에서는 위와 같은 플로우에서 학습할 알고리즘 종류만 바꿔 추후에 활용하기 위해 algorithm이라는 객체에 알고리즘을 할당하는 방식을 사용하였습니다.\n","   * 즉, Gradient boosting을 사용한다면, algorithm 객체에 GBC를 할당하면 되는 것이죠."],"metadata":{"id":"zE9Cq9TGc20y"}},{"cell_type":"code","source":["# Random Forest Clasifier \n","algorithm = RFC\n","algorithm_name = 'rfc'"],"metadata":{"id":"Xtqw7MvYcnJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 기본 모델 학습\n","   * 하이퍼파라미터 튜닝 없이 기본 모델을 학습시켜 봅니다"],"metadata":{"id":"kYFUe-oAd6m0"}},{"cell_type":"code","source":["train_acc_before, test_acc_before = modeling_uncustomized(algorithm, x_train, y_train, x_test, y_test)"],"metadata":{"id":"wSlJt6DMd5ai"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화: (1)학습할 트리 개수 선정\n","   * Random Foest 모델이 학습할 최적의 트리 개수를 선정해 보겠습니다."],"metadata":{"id":"ZqnpAZRwehht"}},{"cell_type":"code","source":["n_estimator_min = 1\n","n_estimator_max = 31\n","optimi_estimator(algorithm, algorithm_name, x_train, y_train, x_test, y_test,\n","                 n_estimator_min, n_estimator_max)"],"metadata":{"id":"jPZ7pHbteKSu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["   * 트리 개수는 많을수록 과적합 방지에 유리합니다. 따라서 트리 개수가 많고 학습 데이터 기반 모델 정확도와 테스트 데이터 기반 모델 정확도의 차이가 적은 값으로 선정하는 것으로 좋습니다. 그래프보다 더욱 정밀하게 하이퍼파라미터별 모델 성능을 알아보기 위해 데이터프레임 형태로도 추이를 출력해 봤습니다\n","   * 트리 개수가 30개 일 때 테스트 데이터 기반 모델 정확도가 가장 높고, 트리 갯수가 더 많아져도 성능에 차이가 없다는 점에, 최적의 트리 개수는 30으로 설정하겠습니다."],"metadata":{"id":"OU9-X07QfZ3m"}},{"cell_type":"code","source":["n_estimator = 30"],"metadata":{"id":"RRfaadp6e3OL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화: (2) 최대 깊이\n","   * Random Forest 모델의 최대 깊이를 선정해 보겠습니다."],"metadata":{"id":"X6ONud5Bf6gi"}},{"cell_type":"code","source":["depth_min = 1\n","depth_max = 21\n","optimi_maxdepth(algorithm, algorithm_name, x_train, y_train, x_test, y_test,\n","                depth_min, depth_max, n_estimator                \n","                )"],"metadata":{"id":"rzVG-X5Hf5t0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["   * 최대 깊이는 적을 수록 과적합 방지에 유리합니다. 따라서 최대 깊이는 적고 학습 데이터 기반 모델 정확도와 테스트 데이터 기반 모델 정확도의 차이가 적은 값으로 선정하는 것이 좋습니다. 아래 그림11과 같이 최대 깊이 값에 따른 모델 성능 추이를 데이터 프레임 형태로 출력해 봤습니다.\n","   * 테스트 데이터 기반 모델 정확도가 점차 증가하다가 감소하기 시작하는 구간으로, 최대 깊이 6을 최적의 값으로 선정하였습니다."],"metadata":{"id":"bUrChilClq49"}},{"cell_type":"code","source":["n_depth = 6"],"metadata":{"id":"16NLYTw4gQy9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화: (3) 분리 노드의 최소 자료 수\n","\n","   * 다음으로 노드를 분리할 때 최소 자료 수의 최적의 값을 선정해 보겠습니다."],"metadata":{"id":"y8d3x_Thlqw7"}},{"cell_type":"code","source":["n_split_min = 1\n","n_split_max = 101\n","# 데이터프레임 행 최대 100개까지 반드시 출력\n","pd.set_option('display.max_row', 100)\n","optimi_minsplit(algorithm, algorithm_name,\n","                x_train, y_train, x_test, y_test,\n","                n_split_min, n_split_max, n_estimator, n_depth)"],"metadata":{"id":"q4S17t3_mJzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["   * 분리 노드의 최소 자료 수에 따른 학습 데이터 및 테스트 데이터에서의 모델 성능은 아래 참고"],"metadata":{"id":"pbul_8AUmcVT"}},{"cell_type":"code","source":["# 분리 노드의 최소 자료수는 많을수록 과적합 방지에 유리, 분리 노드의 최소 자료수는 많게 하되 학습 데이터 기반 모델 정확도와 테스트 데이터 기반 모델 정확도의 차이가 적은 값으로 선정하는 것이 좋다\n","n_split = 66"],"metadata":{"id":"ZWJ8ItSNmbVm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 최적화: (4) 잎사귀 노드의 최소 자료 수"],"metadata":{"id":"RZllwMKkmy0q"}},{"cell_type":"code","source":["n_leaf_min = 1\n","n_leaf_max = 51\n","optimi_minleaf(algorithm, algorithm_name, \n","               x_train, y_train, x_test, y_test, \n","               n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split)"],"metadata":{"id":"l4p1cuA1mx_P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 해석\n","   * 학습 데이터셋 기반 정확도와 테스트 데이터셋 기반 정확도 간의 차이가 적은 잎사귀 노드의 최소 자료 수 선정\n","   * 잎사귀 노드의 최소 자료 수가 클수록 분류 기준이 엄격해져 과대적합 방지가 용이함\n","   * 테스트 데이터셋에서 모델 성능이 증가하다가 감소하기 직전인 최적의 이팟귀 노드의 최소 자료 수 선정"],"metadata":{"id":"RYq64BE0tkJ8"}},{"cell_type":"code","source":["n_leaf = 20"],"metadata":{"id":"b7G1MRsNnFPL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 최종 모델 학습"],"metadata":{"id":"AiFlpd5Dt0UD"}},{"cell_type":"code","source":["model_final(algorithm, algorithm_name, feature_name,\n","            x_train, y_train, x_test, y_test,\n","            n_estimator, n_depth, n_split, n_leaf)"],"metadata":{"id":"Ank-5YA8sKCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install selenium"],"metadata":{"id":"_qV8JYpbaNhb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 해석\n","   * 최종 학습한 모델의 정확도가 99.8%, f1 score 역시 0.999인 만큼 분류 성능이 우수한 것을 알 수 있음\n","   * 변수별 중요도 산출 결과, chlorides(염화물), total sulfur dioxide(총 이산화황), volatile acidity(휘발성산), density(밀도)가 분류에 있어 가장 중요한 4가지 변수임"],"metadata":{"id":"y_jFslrguCHm"}}]}